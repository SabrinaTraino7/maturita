# -*- coding: utf-8 -*-
"""LonziMartina_TrainoSabrina_5BM__Progetto_IA_ML_Classico.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aaVX_A5aj4cdxB1yt4SXG1recCC6gHTT

#PROGETTO MACHINE LEARNING
**Dataset utilizzato per il progetto:** Penguins.csv

**Tencnica di apprendimento del dataset**: Decision Tree


**Realizzato da:** Lonzi Martina e Traino Sabrina

Importazione cartella SEABORN-DATA che contiene il dataset da utilizzare
"""

!git clone https://github.com/mwaskom/seaborn-data.git

"""Importazione del file contenente il dataset "penguins.csv" tramite la libreria di *Python*, Pandas."""

import pandas as pd
df = pd.read_csv('seaborn-data/penguins.csv', header=0)
print(df.head())
print("Dimensioni del dataset:", df.shape)

"""**Importazione delle librerie**

pandas: utilizzato per la manipolazione e l'analisi dei dati.
train_test_split: una funzione di scikit-learn che suddivide un dataset in un set di addestramento e un set di test.
"""

import pandas as pd
from sklearn.model_selection import train_test_split

"""Riepilogo iniziale del dataset che mostra:

Dimensione del dataset: quante righe e colonne contiene.
Anteprima dei dati: le prime cinque righe, per farsi un’idea del loro contenuto.

"""

print("Dimensioni del dataset:", df.shape)
print(df.head())

"""Nel dataset ci sono alcune informazioni rappresentate come parole, come i nomi delle specie di pinguini (Adelie, Chinstrap, Gentoo) e delle isole (Torgersen, Biscoe, Dream). Poiché molti algoritmi di machine learning lavorano meglio con numeri, queste parole vengono tradotte in valori numerici utilizzando dei "dizionari di mappatura":

Ogni specie di pinguino viene convertita in un numero:

Adelie diventa 0, Chinstrap diventa 1, Gentoo diventa 2.

Allo stesso modo, ogni isola ottiene un codice:
Torgersen diventa 0, Biscoe diventa 1, Dream diventa 2.
"""

# Crea un dizionario per mappare le specie ai numeri
species_mapping = {
    'Adelie': 0,
    'Chinstrap': 1,
    'Gentoo': 2
}

# Crea un dizionario per mappare le isole ai numeri
island_mapping = {
    'Torgersen': 0,
    'Biscoe': 1,
    'Dream': 2
}

# Applica la mappatura alle colonne
df['species'] = df['species'].map(species_mapping)
df['island'] = df['island'].map(island_mapping)

"""**Divisione del dataset**

Una volta organizzati i dati, viene effettuata una divisione:

L'80% dei dati viene destinato all'addestramento del modello. Questo è il materiale con cui il programma "imparerà".
Il restante 20% viene riservato per testare il modello. Questo consente di verificare quanto il modello sia efficace nel fare previsioni su dati che non ha mai visto prima.
"""

# Controlla se ci sono valori mancanti e gestiscili
df = df.dropna()  # Rimuove le righe con valori nulli

# Definisci le feature (X) e lel label (y)
X = df[['species', 'island', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']] #dati
y = df['sex']  # Label

# Dividi i dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Output per verifica
print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

"""Importazione del modello *DecisionTreeClassifier*"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

"""Addestramento del modello

**DecisionTreeClassifier:** è un classificatore basato su un albero decisionale, che crea una struttura ad albero per prendere decisioni in base ai dati di input.

random_state=42: garantisce che il risultato sia ripetibile, fissando il seme della generazione casuale.

clf.fit(X_train, y_train): addestra il modello utilizzando i dati di addestramento (X_train come input e y_train come output atteso).

Durante questa fase, il modello apprende i "modelli" o "regole" dai dati.
"""

# Crea e addestra il modello
#clf ->classifier
clf = DecisionTreeClassifier(random_state=42)  # I parametri possono essere personalizzati a propria scelta
clf.fit(X_train, y_train)

"""Una volta addestrato, il modello viene usato per fare previsioni sui dati di test (X_test)."""

# Effettua previsioni
y_pred = clf.predict(X_test)

"""**Valutazione del modello**

Calcolo dell'accuratezza

accuracy_score: confronta le etichette reali (y_test) con quelle previste (y_pred) per calcolare l'accuratezza.

L'accuratezza è la percentuale di previsioni corrette fatte dal modello.

{accuracy:.2f}: stampa l'accuratezza con due cifre decimali.
"""

# Valuta il modello
accuracy = accuracy_score(y_test, y_pred) #calcolo accuratezzacon confronto tra valori reali e predetti
print(f"Accuracy: {accuracy:.2f}")

"""**Report di classificazione**

classification_report: fornisce una panoramica dettagliata delle prestazioni del modello, includendo metriche come:

Precision: quanto le previsioni positive sono corrette.

Recall: quanto bene il modello identifica tutti i casi positivi.

F1-score: una combinazione di precision e recall.

Support: il numero di campioni effettivi per ogni classe.
"""

# Report di classificazione
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Matrice di confusione
labels = ['MALE', 'FEMALE']
conf_matrix= confusion_matrix(y_test, y_pred, labels = labels)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)
plt.xlabel('Etichette predette')
plt.ylabel('Etichette reali')
plt.title('Matrice di confusione')
plt.show()

"""Secondo esempio di DecisionTree, stavolta con parametri del classificatiore diversi."""

# Crea e addestra il modello
#clf ->classifier
clf = DecisionTreeClassifier(criterion= 'entropy',random_state=20)
clf.fit(X_train, y_train)
# Effettua previsioni
y_pred = clf.predict(X_test)
# Valuta il modello
accuracy = accuracy_score(y_test, y_pred) #calcolo accuratezzacon confronto tra valori reali e predetti
print(f"Accuracy: {accuracy:.2f}")
# Report di classificazione
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""Matrice di confusione del secondo DecisionTree"""

# Matrice di confusione
labels = ['MALE', 'FEMALE']
conf_matrix= confusion_matrix(y_test, y_pred, labels = labels)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Reds', xticklabels=labels, yticklabels=labels)
plt.xlabel('Etichette predette')
plt.ylabel('Etichette reali')
plt.title('Matrice di confusione')
plt.show()

"""Basandoci sulle **matrici di confusione** e sui **calcoli dell'accuratezza**, possiamo affermare che il **primo classificatore**, con i parametri di default, performa in modo migliore.

Infatti l'accuratezza del primo è pari a 0.88, mentre quello del secondo è di 0.85.

0.88 > 0.85

Compiendo anche un calcolo per quanto riguarda le etichette predette, si evidenzia come il primo classificatore abbia predette in modo corretto 59 datapoint e ne abbia sbagliato solo 8,
mentre il secondo ne abbia sbagliati 10, ma predetti correttamente 57.
"""

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
data_x = df['species'] #dati da inserire in x
data_y = df['island'] #dati da inserire in y

#lista dei colori in base al genere
colors = ['lightgreen' if gender == 'MALE' else 'red' for gender in df['sex'] ]
scatter =ax.scatter(x=data_x, y=data_y, c=colors)
#in x salvo i dati del vettore data_x, in y quelli del vettore data_y
#mentre nella c salvo i dati nell'array colori
ax.set_xlabel('Specie')
ax.set_ylabel('Isola')
#creazione della legenda
handles, labels = scatter.legend_elements(prop="colors")
ax.legend(handles, ['Maschio', 'Femmina'], title="Maschio = Verde Chiaro \nFemmina = Rosso")
plt.show()

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
data_x = df['bill_length_mm'] #dati da inserire in x
data_y = df['flipper_length_mm'] #dati da inserire in y

#lista dei colori in base al genere
colors = ['lightgreen' if gender == 'MALE' else 'red' for gender in df['sex'] ]
scatter =ax.scatter(x=data_x, y=data_y, c=colors)
#in x salvo i dati del vettore data_x, in y quelli del vettore data_y
#mentre nella c salvo i dati nell'array colori
ax.set_xlabel('Lunghezza Becco (mm)')
ax.set_ylabel('Lunghezza Pinne (mm)')
#creazione della legenda
handles, labels = scatter.legend_elements(prop="colors")
ax.legend(handles, ['Maschio', 'Femmina'], title="Maschio = Verde Chiaro \nFemmina = Rosso")
plt.show()