# -*- coding: utf-8 -*-
"""LonziMartina_TrainoSabrina_5BM__Progetto_IA_Deep_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15OGmkE5ghpRVFr8cCDlOQxnvUEZ5xo_a

#PROGETTO RETI NEURALI
**Dataset utilizzato per il progetto:** LEGO bricks

**Tencnica di apprendimento del dataset**: KNN

**Rete neurale:** CNN


**Realizzato da:** Lonzi Martina e Traino Sabrina

1. Importazioni e setup

  Vengono importate le librerie che servono per la realizzazione della rete neurale, tra cui troviamo matpltlib, per la creazione di grafici e numpy, che fornisce una serie di strumenti per lavorare con grandi array di dati numerici.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import pathlib

"""2. Download del dataset

  Viene scaricato il dataset "LEGO bricks" dalla piattaforma Kaggle,usata per le gare di data science e da professionisti di apprendimento automatico, e viene definito il percorso alla cartella che contiene le immagini organizzate per classe.


"""

#importazione del dataset Lego bricks
import kagglehub

# Download latest version
# setto il percorso alla sottodirectory che contiene le immagini (a sua volta contiene una sottocartella per ogni classe)
path = kagglehub.dataset_download("joosthazelzet/lego-brick-images") + "/LEGO brick images v1"

print("Path to dataset files:", path)
#stringa che rappresenta il percorso sulla macchina dove si trova la cartella del dataset scaricato
dataset_path = pathlib.Path(path)

#preso da kaggle https://www.kaggle.com/code/atulparashar27/lego-bricks-mlp-87-score

DATASET_PATH = path

data = []
labels = []

for subdir in os.listdir(DATASET_PATH):
    subdir_path = os.path.join(DATASET_PATH, subdir)
    if os.path.isdir(subdir_path):
        num_files = len(os.listdir(subdir_path))
        data.append(num_files)
        labels.append(subdir)

fig, ax = plt.subplots(figsize=(12, 8))
ax.bar(labels, data, color='skyblue', edgecolor='black')

ax.set_xlabel('Subdirectories')
ax.set_ylabel('Number of Files')
ax.set_title('Bar plot of Files in Subdirectories')
ax.set_xticks(range(len(labels)))
ax.set_xticklabels(labels, rotation=45, ha='right')

plt.show()

"""3. Caricamento immagini e etichette

  Le immagini dal dataset vengono caricate, ridimensionate e normalizzate. Vengono anche associate le etichette corrette (le classi di mattoncini) ad ogni immagine.

  La normalizzazione si effettuerà in modo che i valori dei pixel siano compresi tra 0 e 1.
"""

def load_images_labels(dataset_path, img_size=(64,64)):
    images = [] #array immagini
    labels = [] #array etichette
    class_names = sorted([d.name for d in dataset_path.iterdir() if d.is_dir()]) #ordinamento delle classi
    print(f"Classi trovate: {class_names}")

    for label_index, class_name in enumerate(class_names): #ciclo sulle classi trovate, ottenendo sia l'indice che il nome della classe
        class_dir = dataset_path / class_name #costruzione del percorso completo della classe
        print(f"Processing class: {class_name} (index: {label_index})") # Debug print
        for img_file in class_dir.glob("*.png"): #cerca le immagini in tutti i file della classe
            img = tf.keras.preprocessing.image.load_img(img_file, target_size=img_size)
            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0 #divisione per normalizzare i valori dei pixel tra 0 e 1
            images.append(img_array)
            labels.append(label_index)
        print(f"Processed {len([f for f in class_dir.glob('*.png')])} images in class {class_name}") # Debug print
    images = np.array(images)
    labels = np.array(labels)
    return images, labels, class_names

"""Utilizzo delle immagini 64x64 trovate per CNN"""

images, labels, class_names = load_images_labels(dataset_path, img_size=(64,64))
print(f"Dataset caricato con {len(images)} immagini.")

"""Visualizzo alcune immagini del datatseti scelto per avere un'idea di ciò su cui la rete neurale deve lavorare."""

# Visualizzo una parte del dataset caricato
plt.figure(figsize=(20,20))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(images[i])
    plt.xlabel(class_names[labels[i]])
plt.show()

"""4. Split train e test

  Il dataset caricato viene suddiviso in due set: uno per l'addestramento del modello (train) e uno per testare le sue performance su dati mai visti prima (test). Le etichette vengono convertite in un formato adatto all'addestramento.

  Saranno presenti degli array che hanno lunghezza pari al numero di clasi trovate.
"""

X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
#Funzione to_categorical per convertire un array di etichette numeriche in un vettore binario
#di lunghezza pari al numero delle classi
y_train_cat = to_categorical(y_train, num_classes=len(class_names))
y_test_cat = to_categorical(y_test, num_classes=len(class_names))
#stampa le dimensioni degli array
print("Shape X_train:", X_train.shape)
print("Shape y_train:", y_train_cat.shape)

"""5. Definizone del modello CNN
  
  Viene costruita una rete neurale convoluzionale (CNN), adatta per il riconoscimento di immagini.
  
  Si definiscono gli strati (convoluzionali, di pooling) tra cui anche il flattene la dense che is attiveranno grazie alla funzione di attivazione ReLu.
"""

#inizio degli strati di convoluzione e di pooling(MaxPooling) con funzione di attivazione ReLu
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    #"appiattisco" i dati riceviìuti in output in modo da ottenre un array a 1 dimensione
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(class_names), activation='softmax')
])
model.summary()
#compilazione del modello
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""Il numero di epoche determina quante volte l'algoritmo di apprendimento lavorerà sull'intero dataset di addestramento. Se il numero di epoche è troppo basso, il modello potrebbe non aver imparato abbastanza. Se è troppo alto, potrebbe portare all'overfitting.

In questo progetto la rete è stata testata inizialmente con una history che comprendeva 25 epoche, poi ne è stata creata un'altra con 50 e infine una con 75.

È stata sceta quella con 75 epoche in quanto rende la rete più efficente e ottimizzata.
"""

#prova con 75 epoche
history = model.fit(X_train, y_train_cat, epochs=75, validation_data=(X_test, y_test_cat))

"""6. Curve di loss e accuracy

  Realizzo dei grafici per evidenziare in modo visivo l'accuratezza e l'errore della rete durante l'addestramento.
  
  Questo aiuta a capire quanto il modello sta imparando.
"""

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss durante addestramento')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.title('Accuracy durante addestramento')
plt.legend()
plt.show()

test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=2)
print(f"Accuracy su test set: {test_acc:.4f}")

"""7. Matrice di confusione

  Si realizza la matrice di confusione, utile per valutare quanto bene il modello stia classificando le diverse classi.

  Le celle sulla diagonale principale rappresentano le previsioni corrette, mentre le altre rappresentano gli errori di classificazione.

  Questo grafico aiuta a identificare eventuali tendenze o aree in cui il modello potrebbe migliorare.
"""

y_pred_prob = model.predict(X_test)
y_pred = np.argmax(y_pred_prob, axis=1)

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xlabel('Predetto')
plt.ylabel('Reale')
plt.title('Matrice di confusione')
plt.show()